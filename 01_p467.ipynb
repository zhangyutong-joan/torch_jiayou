{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两个函数\n",
    "dir():打开，看见<br />\n",
    "help()：说明书"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG',\n",
       " 'AggregationType',\n",
       " 'AnyType',\n",
       " 'Argument',\n",
       " 'ArgumentSpec',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BenchmarkConfig',\n",
       " 'BenchmarkExecutionStats',\n",
       " 'Block',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'BoolType',\n",
       " 'BufferDict',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CONV_BN_FUSION',\n",
       " 'CallStack',\n",
       " 'Capsule',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ClassType',\n",
       " 'Code',\n",
       " 'CompilationUnit',\n",
       " 'CompleteArgumentSpec',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'ComplexType',\n",
       " 'ConcreteModuleType',\n",
       " 'ConcreteModuleTypeBuilder',\n",
       " 'CudaBFloat16StorageBase',\n",
       " 'CudaBoolStorageBase',\n",
       " 'CudaByteStorageBase',\n",
       " 'CudaCharStorageBase',\n",
       " 'CudaComplexDoubleStorageBase',\n",
       " 'CudaComplexFloatStorageBase',\n",
       " 'CudaDoubleStorageBase',\n",
       " 'CudaFloatStorageBase',\n",
       " 'CudaHalfStorageBase',\n",
       " 'CudaIntStorageBase',\n",
       " 'CudaLongStorageBase',\n",
       " 'CudaShortStorageBase',\n",
       " 'DeepCopyMemoTable',\n",
       " 'DeviceObjType',\n",
       " 'DictType',\n",
       " 'DisableTorchFunction',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'EnumType',\n",
       " 'ErrorReport',\n",
       " 'ExecutionPlan',\n",
       " 'FUSE_ADD_RELU',\n",
       " 'FatalError',\n",
       " 'FileCheck',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'FloatType',\n",
       " 'FunctionSchema',\n",
       " 'Future',\n",
       " 'FutureType',\n",
       " 'Generator',\n",
       " 'Gradient',\n",
       " 'Graph',\n",
       " 'GraphExecutorState',\n",
       " 'HOIST_CONV_PACKED_PARAMS',\n",
       " 'HalfStorage',\n",
       " 'HalfStorageBase',\n",
       " 'HalfTensor',\n",
       " 'INSERT_FOLD_PREPACK_OPS',\n",
       " 'IODescriptor',\n",
       " 'InferredType',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'IntType',\n",
       " 'InterfaceType',\n",
       " 'JITException',\n",
       " 'ListType',\n",
       " 'LiteScriptModule',\n",
       " 'LockingLogger',\n",
       " 'LoggerBase',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MobileOptimizerType',\n",
       " 'ModuleDict',\n",
       " 'Node',\n",
       " 'NoneType',\n",
       " 'NoopLogger',\n",
       " 'NumberType',\n",
       " 'OptionalType',\n",
       " 'ParameterDict',\n",
       " 'PyObjectType',\n",
       " 'PyTorchFileReader',\n",
       " 'PyTorchFileWriter',\n",
       " 'QInt32Storage',\n",
       " 'QInt32StorageBase',\n",
       " 'QInt8Storage',\n",
       " 'QInt8StorageBase',\n",
       " 'QUInt4x2Storage',\n",
       " 'QUInt8Storage',\n",
       " 'REMOVE_DROPOUT',\n",
       " 'RRefType',\n",
       " 'SUM',\n",
       " 'ScriptClass',\n",
       " 'ScriptFunction',\n",
       " 'ScriptMethod',\n",
       " 'ScriptModule',\n",
       " 'ScriptObject',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Size',\n",
       " 'StaticRuntime',\n",
       " 'Storage',\n",
       " 'Stream',\n",
       " 'StreamObjType',\n",
       " 'StringType',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tensor',\n",
       " 'TensorType',\n",
       " 'ThroughputBenchmark',\n",
       " 'TracingState',\n",
       " 'TupleType',\n",
       " 'Type',\n",
       " 'USE_GLOBAL_DEPS',\n",
       " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
       " 'Use',\n",
       " 'Value',\n",
       " '_C',\n",
       " '_StorageBase',\n",
       " '_VF',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__future__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_adaptive_avg_pool2d',\n",
       " '_add_batch_dim',\n",
       " '_add_relu',\n",
       " '_add_relu_',\n",
       " '_addmv_impl_',\n",
       " '_aminmax',\n",
       " '_amp_foreach_non_finite_check_and_unscale_',\n",
       " '_amp_update_scale',\n",
       " '_assert',\n",
       " '_autograd_functions',\n",
       " '_baddbmm_mkl_',\n",
       " '_batch_norm_impl_index',\n",
       " '_bmm',\n",
       " '_cast_Byte',\n",
       " '_cast_Char',\n",
       " '_cast_Double',\n",
       " '_cast_Float',\n",
       " '_cast_Half',\n",
       " '_cast_Int',\n",
       " '_cast_Long',\n",
       " '_cast_Short',\n",
       " '_cat',\n",
       " '_choose_qparams_per_tensor',\n",
       " '_classes',\n",
       " '_compute_linear_combination',\n",
       " '_conj',\n",
       " '_convolution',\n",
       " '_convolution_nogroup',\n",
       " '_copy_from',\n",
       " '_ctc_loss',\n",
       " '_cudnn_ctc_loss',\n",
       " '_cudnn_init_dropout_state',\n",
       " '_cudnn_rnn',\n",
       " '_cudnn_rnn_flatten_weight',\n",
       " '_cufft_clear_plan_cache',\n",
       " '_cufft_get_plan_cache_max_size',\n",
       " '_cufft_get_plan_cache_size',\n",
       " '_cufft_set_plan_cache_max_size',\n",
       " '_cummax_helper',\n",
       " '_cummin_helper',\n",
       " '_debug_has_internal_overlap',\n",
       " '_dim_arange',\n",
       " '_dirichlet_grad',\n",
       " '_embedding_bag',\n",
       " '_embedding_bag_forward_only',\n",
       " '_empty_affine_quantized',\n",
       " '_empty_per_channel_affine_quantized',\n",
       " '_euclidean_dist',\n",
       " '_fake_quantize_learnable_per_channel_affine',\n",
       " '_fake_quantize_learnable_per_tensor_affine',\n",
       " '_fft_c2c',\n",
       " '_fft_c2r',\n",
       " '_fft_r2c',\n",
       " '_foreach_abs',\n",
       " '_foreach_abs_',\n",
       " '_foreach_acos',\n",
       " '_foreach_acos_',\n",
       " '_foreach_add',\n",
       " '_foreach_add_',\n",
       " '_foreach_addcdiv',\n",
       " '_foreach_addcdiv_',\n",
       " '_foreach_addcmul',\n",
       " '_foreach_addcmul_',\n",
       " '_foreach_asin',\n",
       " '_foreach_asin_',\n",
       " '_foreach_atan',\n",
       " '_foreach_atan_',\n",
       " '_foreach_ceil',\n",
       " '_foreach_ceil_',\n",
       " '_foreach_cos',\n",
       " '_foreach_cos_',\n",
       " '_foreach_cosh',\n",
       " '_foreach_cosh_',\n",
       " '_foreach_div',\n",
       " '_foreach_div_',\n",
       " '_foreach_erf',\n",
       " '_foreach_erf_',\n",
       " '_foreach_erfc',\n",
       " '_foreach_erfc_',\n",
       " '_foreach_exp',\n",
       " '_foreach_exp_',\n",
       " '_foreach_expm1',\n",
       " '_foreach_expm1_',\n",
       " '_foreach_floor',\n",
       " '_foreach_floor_',\n",
       " '_foreach_frac',\n",
       " '_foreach_frac_',\n",
       " '_foreach_lgamma',\n",
       " '_foreach_lgamma_',\n",
       " '_foreach_log',\n",
       " '_foreach_log10',\n",
       " '_foreach_log10_',\n",
       " '_foreach_log1p',\n",
       " '_foreach_log1p_',\n",
       " '_foreach_log2',\n",
       " '_foreach_log2_',\n",
       " '_foreach_log_',\n",
       " '_foreach_maximum',\n",
       " '_foreach_minimum',\n",
       " '_foreach_mul',\n",
       " '_foreach_mul_',\n",
       " '_foreach_neg',\n",
       " '_foreach_neg_',\n",
       " '_foreach_reciprocal',\n",
       " '_foreach_reciprocal_',\n",
       " '_foreach_round',\n",
       " '_foreach_round_',\n",
       " '_foreach_sigmoid',\n",
       " '_foreach_sigmoid_',\n",
       " '_foreach_sin',\n",
       " '_foreach_sin_',\n",
       " '_foreach_sinh',\n",
       " '_foreach_sinh_',\n",
       " '_foreach_sqrt',\n",
       " '_foreach_sqrt_',\n",
       " '_foreach_sub',\n",
       " '_foreach_sub_',\n",
       " '_foreach_tan',\n",
       " '_foreach_tan_',\n",
       " '_foreach_tanh',\n",
       " '_foreach_tanh_',\n",
       " '_foreach_trunc',\n",
       " '_foreach_trunc_',\n",
       " '_foreach_zero_',\n",
       " '_fused_dropout',\n",
       " '_grid_sampler_2d_cpu_fallback',\n",
       " '_has_compatible_shallow_copy_type',\n",
       " '_import_dotted_name',\n",
       " '_index_copy_',\n",
       " '_index_put_impl_',\n",
       " '_initExtension',\n",
       " '_jit_internal',\n",
       " '_linalg_inv_out_helper_',\n",
       " '_linalg_qr_helper',\n",
       " '_linalg_solve_out_helper_',\n",
       " '_linalg_utils',\n",
       " '_load_global_deps',\n",
       " '_lobpcg',\n",
       " '_log_softmax',\n",
       " '_log_softmax_backward_data',\n",
       " '_logcumsumexp',\n",
       " '_lowrank',\n",
       " '_lu_solve_helper',\n",
       " '_lu_with_info',\n",
       " '_make_dual',\n",
       " '_make_per_channel_quantized_tensor',\n",
       " '_make_per_tensor_quantized_tensor',\n",
       " '_masked_scale',\n",
       " '_mkldnn',\n",
       " '_mkldnn_reshape',\n",
       " '_mkldnn_transpose',\n",
       " '_mkldnn_transpose_',\n",
       " '_mode',\n",
       " '_namedtensor_internals',\n",
       " '_nnpack_available',\n",
       " '_nnpack_spatial_convolution',\n",
       " '_ops',\n",
       " '_pack_padded_sequence',\n",
       " '_pad_packed_sequence',\n",
       " '_remove_batch_dim',\n",
       " '_reshape_from_tensor',\n",
       " '_rowwise_prune',\n",
       " '_s_where',\n",
       " '_sample_dirichlet',\n",
       " '_saturate_weight_to_fp16',\n",
       " '_shape_as_tensor',\n",
       " '_six',\n",
       " '_sobol_engine_draw',\n",
       " '_sobol_engine_ff_',\n",
       " '_sobol_engine_initialize_state_',\n",
       " '_sobol_engine_scramble_',\n",
       " '_softmax',\n",
       " '_softmax_backward_data',\n",
       " '_sparse_addmm',\n",
       " '_sparse_coo_tensor_unsafe',\n",
       " '_sparse_log_softmax',\n",
       " '_sparse_log_softmax_backward_data',\n",
       " '_sparse_matrix_mask_helper',\n",
       " '_sparse_mm',\n",
       " '_sparse_softmax',\n",
       " '_sparse_softmax_backward_data',\n",
       " '_sparse_sparse_matmul',\n",
       " '_sparse_sum',\n",
       " '_stack',\n",
       " '_standard_gamma',\n",
       " '_standard_gamma_grad',\n",
       " '_std',\n",
       " '_storage_classes',\n",
       " '_string_classes',\n",
       " '_syevd_helper',\n",
       " '_tensor_classes',\n",
       " '_tensor_str',\n",
       " '_test_serialization_subcmul',\n",
       " '_trilinear',\n",
       " '_unique',\n",
       " '_unique2',\n",
       " '_unpack_dual',\n",
       " '_use_cudnn_ctc_loss',\n",
       " '_use_cudnn_rnn_flatten_weight',\n",
       " '_utils',\n",
       " '_utils_internal',\n",
       " '_validate_sparse_coo_tensor_args',\n",
       " '_var',\n",
       " '_vmap_internals',\n",
       " '_weight_norm',\n",
       " '_weight_norm_cuda_interface',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'adaptive_avg_pool1d',\n",
       " 'adaptive_max_pool1d',\n",
       " 'add',\n",
       " 'addbmm',\n",
       " 'addcdiv',\n",
       " 'addcmul',\n",
       " 'addmm',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'affine_grid_generator',\n",
       " 'align_tensors',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alpha_dropout',\n",
       " 'alpha_dropout_',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'are_deterministic_algorithms_enabled',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_tensor',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'autocast_decrement_nesting',\n",
       " 'autocast_increment_nesting',\n",
       " 'autograd',\n",
       " 'avg_pool1d',\n",
       " 'backends',\n",
       " 'baddbmm',\n",
       " 'bartlett_window',\n",
       " 'batch_norm',\n",
       " 'batch_norm_backward_elemt',\n",
       " 'batch_norm_backward_reduce',\n",
       " 'batch_norm_elemt',\n",
       " 'batch_norm_gather_stats',\n",
       " 'batch_norm_gather_stats_with_counts',\n",
       " 'batch_norm_stats',\n",
       " 'batch_norm_update_stats',\n",
       " 'bernoulli',\n",
       " 'bfloat16',\n",
       " 'bilinear',\n",
       " 'binary_cross_entropy_with_logits',\n",
       " 'bincount',\n",
       " 'binomial',\n",
       " 'bitwise_and',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_xor',\n",
       " 'blackman_window',\n",
       " 'block_diag',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_shapes',\n",
       " 'broadcast_tensors',\n",
       " 'broadcast_to',\n",
       " 'bucketize',\n",
       " 'can_cast',\n",
       " 'cartesian_prod',\n",
       " 'cat',\n",
       " 'cdist',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'celu',\n",
       " 'celu_',\n",
       " 'cfloat',\n",
       " 'chain_matmul',\n",
       " 'channel_shuffle',\n",
       " 'channels_last',\n",
       " 'channels_last_3d',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'choose_qparams_optimized',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'classes',\n",
       " 'clear_autocast_cache',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'column_stack',\n",
       " 'combinations',\n",
       " 'compiled_with_cxx11_abi',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex32',\n",
       " 'complex64',\n",
       " 'conj',\n",
       " 'constant_pad_nd',\n",
       " 'contiguous_format',\n",
       " 'conv1d',\n",
       " 'conv2d',\n",
       " 'conv3d',\n",
       " 'conv_tbc',\n",
       " 'conv_transpose1d',\n",
       " 'conv_transpose2d',\n",
       " 'conv_transpose3d',\n",
       " 'convolution',\n",
       " 'copysign',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cosine_embedding_loss',\n",
       " 'cosine_similarity',\n",
       " 'count_nonzero',\n",
       " 'cpp',\n",
       " 'cross',\n",
       " 'ctc_loss',\n",
       " 'ctypes',\n",
       " 'cuda',\n",
       " 'cudnn_affine_grid_generator',\n",
       " 'cudnn_batch_norm',\n",
       " 'cudnn_convolution',\n",
       " 'cudnn_convolution_transpose',\n",
       " 'cudnn_grid_sampler',\n",
       " 'cudnn_is_acceptable',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'default_generator',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'dist',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout_',\n",
       " 'dsmm',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'einsum',\n",
       " 'embedding',\n",
       " 'embedding_bag',\n",
       " 'embedding_renorm_',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'empty_meta',\n",
       " 'empty_quantized',\n",
       " 'empty_strided',\n",
       " 'enable_grad',\n",
       " 'eq',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'eye',\n",
       " 'fake_quantize_per_channel_affine',\n",
       " 'fake_quantize_per_tensor_affine',\n",
       " 'fbgemm_linear_fp16_weight',\n",
       " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
       " 'fbgemm_linear_int8_weight',\n",
       " 'fbgemm_linear_int8_weight_fp32_activation',\n",
       " 'fbgemm_linear_quantize_weight',\n",
       " 'fbgemm_pack_gemm_matrix_fp16',\n",
       " 'fbgemm_pack_quantized_matrix',\n",
       " 'feature_alpha_dropout',\n",
       " 'feature_alpha_dropout_',\n",
       " 'feature_dropout',\n",
       " 'feature_dropout_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_power',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fork',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frobenius_norm',\n",
       " 'from_file',\n",
       " 'from_numpy',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'functional',\n",
       " 'futures',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_default_dtype',\n",
       " 'get_device',\n",
       " 'get_file_path',\n",
       " 'get_num_interop_threads',\n",
       " 'get_num_threads',\n",
       " 'get_rng_state',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'grid_sampler',\n",
       " 'grid_sampler_2d',\n",
       " 'grid_sampler_3d',\n",
       " 'group_norm',\n",
       " 'gru',\n",
       " 'gru_cell',\n",
       " 'gt',\n",
       " 'half',\n",
       " 'hamming_window',\n",
       " 'hann_window',\n",
       " 'hardshrink',\n",
       " 'has_cuda',\n",
       " 'has_cudnn',\n",
       " 'has_lapack',\n",
       " 'has_mkl',\n",
       " 'has_mkldnn',\n",
       " 'has_openmp',\n",
       " 'heaviside',\n",
       " 'hinge_embedding_loss',\n",
       " 'histc',\n",
       " 'hsmm',\n",
       " 'hspmm',\n",
       " 'hstack',\n",
       " 'hub',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'import_ir_module',\n",
       " 'import_ir_module_from_buffer',\n",
       " 'index_add',\n",
       " 'index_copy',\n",
       " 'index_fill',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'init_num_threads',\n",
       " 'initial_seed',\n",
       " 'inner',\n",
       " 'instance_norm',\n",
       " 'int',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_anomaly_enabled',\n",
       " 'is_autocast_enabled',\n",
       " 'is_complex',\n",
       " 'is_deterministic',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_grad_enabled',\n",
       " 'is_nonzero',\n",
       " 'is_same_size',\n",
       " 'is_signed',\n",
       " 'is_storage',\n",
       " 'is_tensor',\n",
       " 'is_vulkan_available',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'jit',\n",
       " 'kaiser_window',\n",
       " 'kl_div',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'layer_norm',\n",
       " 'layout',\n",
       " 'lcm',\n",
       " 'lcm_',\n",
       " 'ldexp',\n",
       " 'ldexp_',\n",
       " 'le',\n",
       " 'legacy_contiguous_format',\n",
       " 'lerp',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'load',\n",
       " 'lobpcg',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_softmax',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logcumsumexp',\n",
       " 'logdet',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logit',\n",
       " 'logit_',\n",
       " 'logspace',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstm',\n",
       " 'lstm_cell',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'lu_unpack',\n",
       " 'manual_seed',\n",
       " 'margin_ranking_loss',\n",
       " 'masked_fill',\n",
       " 'masked_scatter',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_exp',\n",
       " 'matrix_power',\n",
       " 'matrix_rank',\n",
       " 'max',\n",
       " 'max_pool1d',\n",
       " 'max_pool1d_with_indices',\n",
       " 'max_pool2d',\n",
       " 'max_pool3d',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_format',\n",
       " 'merge_type_from_type_comment',\n",
       " 'meshgrid',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'miopen_batch_norm',\n",
       " 'miopen_convolution',\n",
       " 'miopen_convolution_transpose',\n",
       " 'miopen_depthwise_convolution',\n",
       " 'miopen_rnn',\n",
       " 'mkldnn_adaptive_avg_pool2d',\n",
       " 'mkldnn_convolution',\n",
       " 'mkldnn_convolution_backward_weights',\n",
       " 'mkldnn_linear_backward_weights',\n",
       " 'mkldnn_max_pool2d',\n",
       " 'mkldnn_max_pool3d',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'moveaxis',\n",
       " 'movedim',\n",
       " 'msort',\n",
       " 'mul',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'multiprocessing',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'name',\n",
       " 'nan_to_num',\n",
       " 'nan_to_num_',\n",
       " 'nanmedian',\n",
       " 'nanquantile',\n",
       " 'nansum',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'native_batch_norm',\n",
       " 'native_group_norm',\n",
       " 'native_layer_norm',\n",
       " 'native_norm',\n",
       " 'ne',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'negative',\n",
       " 'negative_',\n",
       " 'nextafter',\n",
       " 'nn',\n",
       " 'no_grad',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'norm_except_dim',\n",
       " 'normal',\n",
       " 'not_equal',\n",
       " 'nuclear_norm',\n",
       " 'numel',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'onnx',\n",
       " 'ops',\n",
       " 'optim',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'os',\n",
       " 'outer',\n",
       " 'overrides',\n",
       " 'pairwise_distance',\n",
       " 'parse_ir',\n",
       " 'parse_schema',\n",
       " 'parse_type_comment',\n",
       " 'pca_lowrank',\n",
       " 'pdist',\n",
       " 'per_channel_affine',\n",
       " 'per_channel_affine_float_qparams',\n",
       " 'per_channel_symmetric',\n",
       " 'per_tensor_affine',\n",
       " 'per_tensor_symmetric',\n",
       " 'pinverse',\n",
       " 'pixel_shuffle',\n",
       " 'pixel_unshuffle',\n",
       " 'platform',\n",
       " 'poisson',\n",
       " 'poisson_nll_loss',\n",
       " 'polar',\n",
       " 'polygamma',\n",
       " 'pow',\n",
       " 'prelu',\n",
       " 'prepare_multiprocessing_environment',\n",
       " 'preserve_format',\n",
       " 'prod',\n",
       " 'profiler',\n",
       " 'promote_types',\n",
       " 'q_per_channel_axis',\n",
       " 'q_per_channel_scales',\n",
       " 'q_per_channel_zero_points',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'quantile',\n",
       " 'quantization',\n",
       " 'quantize_per_channel',\n",
       " 'quantize_per_tensor',\n",
       " 'quantized_batch_norm',\n",
       " 'quantized_gru',\n",
       " 'quantized_gru_cell',\n",
       " 'quantized_lstm',\n",
       " 'quantized_lstm_cell',\n",
       " 'quantized_max_pool1d',\n",
       " 'quantized_max_pool2d',\n",
       " 'quantized_rnn_relu_cell',\n",
       " 'quantized_rnn_tanh_cell',\n",
       " 'quasirandom',\n",
       " 'quint4x2',\n",
       " 'quint8',\n",
       " 'rad2deg',\n",
       " 'rad2deg_',\n",
       " 'rand',\n",
       " 'rand_like',\n",
       " 'randint',\n",
       " 'randint_like',\n",
       " 'randn',\n",
       " 'randn_like',\n",
       " 'random',\n",
       " 'randperm',\n",
       " 'range',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'renorm',\n",
       " 'repeat_interleave',\n",
       " 'reshape',\n",
       " 'resize_as_',\n",
       " 'result_type',\n",
       " 'rnn_relu',\n",
       " 'rnn_relu_cell',\n",
       " 'rnn_tanh',\n",
       " 'rnn_tanh_cell',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'row_stack',\n",
       " 'rrelu',\n",
       " 'rrelu_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'rsub',\n",
       " 'saddmm',\n",
       " 'save',\n",
       " 'scalar_tensor',\n",
       " 'scatter',\n",
       " 'scatter_add',\n",
       " 'searchsorted',\n",
       " 'seed',\n",
       " 'select',\n",
       " 'selu',\n",
       " 'selu_',\n",
       " 'serialization',\n",
       " 'set_anomaly_enabled',\n",
       " 'set_autocast_enabled',\n",
       " 'set_default_dtype',\n",
       " 'set_default_tensor_type',\n",
       " 'set_deterministic',\n",
       " 'set_flush_denormal',\n",
       " 'set_grad_enabled',\n",
       " 'set_num_interop_threads',\n",
       " 'set_num_threads',\n",
       " 'set_printoptions',\n",
       " 'set_rng_state',\n",
       " 'sgn',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'signbit',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinc',\n",
       " 'sinc_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse',\n",
       " 'sparse_coo',\n",
       " 'sparse_coo_tensor',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'spmm',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'square',\n",
       " 'square_',\n",
       " 'squeeze',\n",
       " 'sspaddmm',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'std_mean',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'strided',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'svd',\n",
       " 'svd_lowrank',\n",
       " 'swapaxes',\n",
       " 'swapdims',\n",
       " 'symeig',\n",
       " 'sys',\n",
       " 't',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'tensor',\n",
       " 'tensor_split',\n",
       " 'tensordot',\n",
       " 'testing',\n",
       " 'textwrap',\n",
       " 'threshold',\n",
       " 'threshold_',\n",
       " 'tile',\n",
       " 'topk',\n",
       " 'torch',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'trapz',\n",
       " 'triangular_solve',\n",
       " 'tril',\n",
       " 'tril_indices',\n",
       " 'triplet_margin_loss',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch) # 输出更小的工具箱们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch.cuda in torch:\n",
      "\n",
      "NAME\n",
      "    torch.cuda\n",
      "\n",
      "DESCRIPTION\n",
      "    This package adds support for CUDA tensor types, that implement the same\n",
      "    function as CPU tensors, but they utilize GPUs for computation.\n",
      "    \n",
      "    It is lazily initialized, so you can always import it, and use\n",
      "    :func:`is_available()` to determine if your system supports CUDA.\n",
      "    \n",
      "    :ref:`cuda-semantics` has more details about working with CUDA.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _utils\n",
      "    amp (package)\n",
      "    comm\n",
      "    error\n",
      "    graphs\n",
      "    memory\n",
      "    nccl\n",
      "    nvtx\n",
      "    profiler\n",
      "    random\n",
      "    sparse\n",
      "    streams\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        DeferredCudaCallError\n",
      "    builtins.RuntimeError(builtins.Exception)\n",
      "        CudaError\n",
      "    builtins.object\n",
      "        BFloat16Tensor\n",
      "        BoolTensor\n",
      "        ByteTensor\n",
      "        CharTensor\n",
      "        DoubleTensor\n",
      "        FloatTensor\n",
      "        HalfTensor\n",
      "        IntTensor\n",
      "        LongTensor\n",
      "        ShortTensor\n",
      "        cudaStatus\n",
      "        device\n",
      "            device_of\n",
      "    torch._C.CudaBFloat16StorageBase(builtins.object)\n",
      "        BFloat16Storage(_CudaBase, torch._C.CudaBFloat16StorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaBoolStorageBase(builtins.object)\n",
      "        BoolStorage(_CudaBase, torch._C.CudaBoolStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaByteStorageBase(builtins.object)\n",
      "        ByteStorage(_CudaBase, torch._C.CudaByteStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaCharStorageBase(builtins.object)\n",
      "        CharStorage(_CudaBase, torch._C.CudaCharStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaComplexDoubleStorageBase(builtins.object)\n",
      "        ComplexDoubleStorage(_CudaBase, torch._C.CudaComplexDoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaComplexFloatStorageBase(builtins.object)\n",
      "        ComplexFloatStorage(_CudaBase, torch._C.CudaComplexFloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaDoubleStorageBase(builtins.object)\n",
      "        DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaFloatStorageBase(builtins.object)\n",
      "        FloatStorage(_CudaBase, torch._C.CudaFloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaHalfStorageBase(builtins.object)\n",
      "        HalfStorage(_CudaBase, torch._C.CudaHalfStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaIntStorageBase(builtins.object)\n",
      "        IntStorage(_CudaBase, torch._C.CudaIntStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaLongStorageBase(builtins.object)\n",
      "        LongStorage(_CudaBase, torch._C.CudaLongStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CudaShortStorageBase(builtins.object)\n",
      "        ShortStorage(_CudaBase, torch._C.CudaShortStorageBase, torch.storage._StorageBase)\n",
      "    _CudaBase(builtins.object)\n",
      "        BFloat16Storage(_CudaBase, torch._C.CudaBFloat16StorageBase, torch.storage._StorageBase)\n",
      "        BoolStorage(_CudaBase, torch._C.CudaBoolStorageBase, torch.storage._StorageBase)\n",
      "        ByteStorage(_CudaBase, torch._C.CudaByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(_CudaBase, torch._C.CudaCharStorageBase, torch.storage._StorageBase)\n",
      "        ComplexDoubleStorage(_CudaBase, torch._C.CudaComplexDoubleStorageBase, torch.storage._StorageBase)\n",
      "        ComplexFloatStorage(_CudaBase, torch._C.CudaComplexFloatStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(_CudaBase, torch._C.CudaFloatStorageBase, torch.storage._StorageBase)\n",
      "        HalfStorage(_CudaBase, torch._C.CudaHalfStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(_CudaBase, torch._C.CudaIntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(_CudaBase, torch._C.CudaLongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(_CudaBase, torch._C.CudaShortStorageBase, torch.storage._StorageBase)\n",
      "    torch.storage._StorageBase(builtins.object)\n",
      "        BFloat16Storage(_CudaBase, torch._C.CudaBFloat16StorageBase, torch.storage._StorageBase)\n",
      "        BoolStorage(_CudaBase, torch._C.CudaBoolStorageBase, torch.storage._StorageBase)\n",
      "        ByteStorage(_CudaBase, torch._C.CudaByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(_CudaBase, torch._C.CudaCharStorageBase, torch.storage._StorageBase)\n",
      "        ComplexDoubleStorage(_CudaBase, torch._C.CudaComplexDoubleStorageBase, torch.storage._StorageBase)\n",
      "        ComplexFloatStorage(_CudaBase, torch._C.CudaComplexFloatStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(_CudaBase, torch._C.CudaFloatStorageBase, torch.storage._StorageBase)\n",
      "        HalfStorage(_CudaBase, torch._C.CudaHalfStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(_CudaBase, torch._C.CudaIntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(_CudaBase, torch._C.CudaLongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(_CudaBase, torch._C.CudaShortStorageBase, torch.storage._StorageBase)\n",
      "    \n",
      "    class BFloat16Storage(_CudaBase, torch._C.CudaBFloat16StorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      BFloat16Storage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaBFloat16StorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaBFloat16StorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaBFloat16StorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaBFloat16StorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class BFloat16Tensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.bfloat16\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class BoolStorage(_CudaBase, torch._C.CudaBoolStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      BoolStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaBoolStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaBoolStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaBoolStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaBoolStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class BoolTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.bool\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ByteStorage(_CudaBase, torch._C.CudaByteStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ByteStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaByteStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaByteStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaByteStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaByteStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class ByteTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.uint8\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CharStorage(_CudaBase, torch._C.CudaCharStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      CharStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaCharStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaCharStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaCharStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaCharStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class CharTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int8\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ComplexDoubleStorage(_CudaBase, torch._C.CudaComplexDoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ComplexDoubleStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaComplexDoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaComplexDoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaComplexDoubleStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaComplexDoubleStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class ComplexFloatStorage(_CudaBase, torch._C.CudaComplexFloatStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ComplexFloatStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaComplexFloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaComplexFloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaComplexFloatStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaComplexFloatStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class CudaError(builtins.RuntimeError)\n",
      "     |  Unspecified run-time error.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CudaError\n",
      "     |      builtins.RuntimeError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, code:int) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.RuntimeError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class DeferredCudaCallError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeferredCudaCallError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      DoubleStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaDoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaDoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaDoubleStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaDoubleStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class DoubleTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float64\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class FloatStorage(_CudaBase, torch._C.CudaFloatStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      FloatStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaFloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaFloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaFloatStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaFloatStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class FloatTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float32\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class HalfStorage(_CudaBase, torch._C.CudaHalfStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      HalfStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaHalfStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaHalfStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaHalfStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaHalfStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class HalfTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float16\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class IntStorage(_CudaBase, torch._C.CudaIntStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      IntStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaIntStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaIntStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaIntStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaIntStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class IntTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int32\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class LongStorage(_CudaBase, torch._C.CudaLongStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      LongStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaLongStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaLongStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaLongStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaLongStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class LongTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int64\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ShortStorage(_CudaBase, torch._C.CudaShortStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ShortStorage\n",
      "     |      _CudaBase\n",
      "     |      torch._C.CudaShortStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  type(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from _CudaBase:\n",
      "     |  \n",
      "     |  __new__ = _lazy_new(cls, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _CudaBase:\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CudaShortStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CudaShortStorageBase:\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CudaShortStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bfloat16(self)\n",
      "     |      Casts this storage to bfloat16 type\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  complex_double(self)\n",
      "     |      Casts this storage to complex double type\n",
      "     |  \n",
      "     |  complex_float(self)\n",
      "     |      Casts this storage to complex float type\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cdata': typing.Any, 'is_cuda': <class 'bool'>, 'i...\n",
      "    \n",
      "    class ShortTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __complex__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ifloordiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imod__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from torch.tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  absolute(...)\n",
      "     |      absolute() -> Tensor\n",
      "     |      \n",
      "     |      Alias for :func:`abs`\n",
      "     |  \n",
      "     |  absolute_(...)\n",
      "     |      absolute_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.absolute`\n",
      "     |      Alias for :func:`abs_`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  acosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acosh`\n",
      "     |  \n",
      "     |  acosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acosh`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`\n",
      "     |      and :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`alpha` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(tensor1, tensor2, *, value=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  align_as(...)\n",
      "     |      align_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the dimension order\n",
      "     |      in the :attr:`other` tensor, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      This operation is useful for explicit broadcasting by names (see examples).\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in ``other.names``.\n",
      "     |      :attr:`other` may contain named dimensions that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      To align a tensor to a specific order, use :meth:`~Tensor.align_to`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          # Example 1: Applying a mask\n",
      "     |          >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')\n",
      "     |          >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> imgs.masked_fill_(mask.align_as(imgs), 0)\n",
      "     |      \n",
      "     |      \n",
      "     |          # Example 2: Applying a per-channel-scale\n",
      "     |          >>> def scale_channels(input, scale):\n",
      "     |          >>>    scale = scale.refine_names('C')\n",
      "     |          >>>    return input * scale.align_as(input)\n",
      "     |      \n",
      "     |          >>> num_channels = 3\n",
      "     |          >>> scale = torch.randn(num_channels, names=('C',))\n",
      "     |          >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))\n",
      "     |          >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))\n",
      "     |      \n",
      "     |          # scale_channels is agnostic to the dimension order of the input\n",
      "     |          >>> scale_channels(imgs, scale)\n",
      "     |          >>> scale_channels(more_imgs, scale)\n",
      "     |          >>> scale_channels(videos, scale)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  align_to(self, *names)\n",
      "     |      Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "     |      specified in :attr:`names`, adding size-one dims for any new names.\n",
      "     |      \n",
      "     |      All of the dims of :attr:`self` must be named in order to use this method.\n",
      "     |      The resulting tensor is a view on the original tensor.\n",
      "     |      \n",
      "     |      All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "     |      :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "     |      the output tensor has a size-one dimension for each of those new names.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "     |      that are not mentioned in :attr:`names`, in the order that they appear\n",
      "     |      in :attr:`self`.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired dimension ordering of the\n",
      "     |              output tensor. May contain up to one Ellipsis that is expanded\n",
      "     |              to all unmentioned dim names of :attr:`self`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "     |          >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "     |      \n",
      "     |          # Move the F and E dims to the front while keeping the rest in order\n",
      "     |          >>> named_tensor.align_to('F', 'E', ...)\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      all(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.all`\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  amax(...)\n",
      "     |      amax(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amax`\n",
      "     |  \n",
      "     |  amin(...)\n",
      "     |      amin(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.amin`\n",
      "     |  \n",
      "     |  angle(...)\n",
      "     |      angle() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.angle`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      any(dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.any`\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  arccos(...)\n",
      "     |      arccos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccos`\n",
      "     |  \n",
      "     |  arccos_(...)\n",
      "     |      arccos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccos`\n",
      "     |  \n",
      "     |  arccosh(...)\n",
      "     |      acosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arccosh`\n",
      "     |  \n",
      "     |  arccosh_(...)\n",
      "     |      acosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arccosh`\n",
      "     |  \n",
      "     |  arcsin(...)\n",
      "     |      arcsin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsin`\n",
      "     |  \n",
      "     |  arcsin_(...)\n",
      "     |      arcsin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsin`\n",
      "     |  \n",
      "     |  arcsinh(...)\n",
      "     |      arcsinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arcsinh`\n",
      "     |  \n",
      "     |  arcsinh_(...)\n",
      "     |      arcsinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arcsinh`\n",
      "     |  \n",
      "     |  arctan(...)\n",
      "     |      arctan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctan`\n",
      "     |  \n",
      "     |  arctan_(...)\n",
      "     |      arctan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctan`\n",
      "     |  \n",
      "     |  arctanh(...)\n",
      "     |      arctanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.arctanh`\n",
      "     |  \n",
      "     |  arctanh_(...)\n",
      "     |      arctanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.arctanh`\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |      as_strided(size, stride, storage_offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.as_strided`\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  as_subclass(...)\n",
      "     |      as_subclass(cls) -> Tensor\n",
      "     |      \n",
      "     |      Makes a ``cls`` instance with the same data pointer as ``self``. Changes\n",
      "     |      in the output mirror changes in ``self``, and the output stays attached\n",
      "     |      to the autograd graph. ``cls`` must be a subclass of ``Tensor``.\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  asinh(...)\n",
      "     |      asinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asinh`\n",
      "     |  \n",
      "     |  asinh_(...)\n",
      "     |      asinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asinh`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  atanh(...)\n",
      "     |      atanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atanh`\n",
      "     |  \n",
      "     |  atanh_(...)\n",
      "     |      atanh_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atanh`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to zero\n",
      "     |      ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "     |      See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "     |      for details on the memory layout of accumulated gradients.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "     |          in a user-specified CUDA stream context, see\n",
      "     |          :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |          inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "     |              accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "     |              provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "     |              used to compute the attr::tensors. All the provided inputs must be leaf\n",
      "     |              Tensors.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bfloat16(...)\n",
      "     |      bfloat16(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      ``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bitwise_and(...)\n",
      "     |      bitwise_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_and_(...)\n",
      "     |      bitwise_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_and`\n",
      "     |  \n",
      "     |  bitwise_not(...)\n",
      "     |      bitwise_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_not_(...)\n",
      "     |      bitwise_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_not`\n",
      "     |  \n",
      "     |  bitwise_or(...)\n",
      "     |      bitwise_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_or_(...)\n",
      "     |      bitwise_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_or`\n",
      "     |  \n",
      "     |  bitwise_xor(...)\n",
      "     |      bitwise_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bitwise_xor`\n",
      "     |  \n",
      "     |  bitwise_xor_(...)\n",
      "     |      bitwise_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.bitwise_xor`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  bool(...)\n",
      "     |      bool(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  broadcast_to(...)\n",
      "     |      broadcast_to(shape) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.broadcast_to`.\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clip(...)\n",
      "     |      clip(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp`.\n",
      "     |  \n",
      "     |  clip_(...)\n",
      "     |      clip_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.clamp_`.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone(*, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clone`\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |      coalesce() -> Tensor\n",
      "     |      \n",
      "     |      Returns a coalesced copy of :attr:`self` if :attr:`self` is an\n",
      "     |      :ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.\n",
      "     |      \n",
      "     |      Returns :attr:`self` if :attr:`self` is a coalesced tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |  \n",
      "     |  conj(...)\n",
      "     |      conj() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.conj`\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is already in the specified memory format, this function returns the\n",
      "     |      :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  copysign(...)\n",
      "     |      copysign(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.copysign`\n",
      "     |  \n",
      "     |  copysign_(...)\n",
      "     |      copysign_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.copysign`\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  count_nonzero(...)\n",
      "     |      count_nonzero(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.count_nonzero`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  cummax(...)\n",
      "     |      cummax(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummax`\n",
      "     |  \n",
      "     |  cummin(...)\n",
      "     |      cummin(dim) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.cummin`\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumprod_(...)\n",
      "     |      cumprod_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  cumsum_(...)\n",
      "     |      cumsum_(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  deg2rad(...)\n",
      "     |      deg2rad() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.deg2rad`\n",
      "     |  \n",
      "     |  deg2rad_(...)\n",
      "     |      deg2rad_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.deg2rad`\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(offset=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  diff(...)\n",
      "     |      diff(n=1, dim=-1, prepend=None, append=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diff`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  divide(...)\n",
      "     |      divide(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.divide`\n",
      "     |  \n",
      "     |  divide_(...)\n",
      "     |      divide_(value, *, rounding_mode=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.divide`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp2(...)\n",
      "     |      exp2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp2`\n",
      "     |  \n",
      "     |  exp2_(...)\n",
      "     |      exp2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp2`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  fill_diagonal_(...)\n",
      "     |      fill_diagonal_(fill_value, wrap=False) -> Tensor\n",
      "     |      \n",
      "     |      Fill the main diagonal of a tensor that has at least 2-dimensions.\n",
      "     |      When dims>2, all dimensions of input must be of equal length.\n",
      "     |      This function modifies the input tensor in-place, and returns the input tensor.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          fill_value (Scalar): the fill value\n",
      "     |          wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.zeros(3, 3)\n",
      "     |          >>> a.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |          >>> b = torch.zeros(7, 3)\n",
      "     |          >>> b.fill_diagonal_(5)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [0., 0., 0.]])\n",
      "     |          >>> c = torch.zeros(7, 3)\n",
      "     |          >>> c.fill_diagonal_(5, wrap=True)\n",
      "     |          tensor([[5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.],\n",
      "     |                  [0., 0., 0.],\n",
      "     |                  [5., 0., 0.],\n",
      "     |                  [0., 5., 0.],\n",
      "     |                  [0., 0., 5.]])\n",
      "     |  \n",
      "     |  fix(...)\n",
      "     |      fix() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fix`.\n",
      "     |  \n",
      "     |  fix_(...)\n",
      "     |      fix_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fix`\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  fliplr(...)\n",
      "     |      fliplr() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fliplr`\n",
      "     |  \n",
      "     |  flipud(...)\n",
      "     |      flipud() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flipud`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  float_power(...)\n",
      "     |      float_power(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.float_power`\n",
      "     |  \n",
      "     |  float_power_(...)\n",
      "     |      float_power_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.float_power`\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  floor_divide(...)\n",
      "     |      floor_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor_divide`\n",
      "     |  \n",
      "     |  floor_divide_(...)\n",
      "     |      floor_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor_divide`\n",
      "     |  \n",
      "     |  fmax(...)\n",
      "     |      fmax(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmax`\n",
      "     |  \n",
      "     |  fmin(...)\n",
      "     |      fmin(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmin`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  gcd(...)\n",
      "     |      gcd(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gcd`\n",
      "     |  \n",
      "     |  gcd_(...)\n",
      "     |      gcd_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gcd`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`.\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`.\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = p^{k - 1} (1 - p)\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  greater(...)\n",
      "     |      greater(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater`.\n",
      "     |  \n",
      "     |  greater_(...)\n",
      "     |      greater_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater`.\n",
      "     |  \n",
      "     |  greater_equal(...)\n",
      "     |      greater_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.greater_equal`.\n",
      "     |  \n",
      "     |  greater_equal_(...)\n",
      "     |      greater_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.greater_equal`.\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`.\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`.\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  has_names(...)\n",
      "     |      Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.\n",
      "     |  \n",
      "     |  heaviside(...)\n",
      "     |      heaviside(values) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.heaviside`\n",
      "     |  \n",
      "     |  heaviside_(...)\n",
      "     |      heaviside_(values) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.heaviside`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  hypot(...)\n",
      "     |      hypot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.hypot`\n",
      "     |  \n",
      "     |  hypot_(...)\n",
      "     |      hypot_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.hypot`\n",
      "     |  \n",
      "     |  i0(...)\n",
      "     |      i0() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.i0`\n",
      "     |  \n",
      "     |  i0_(...)\n",
      "     |      i0_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.i0`\n",
      "     |  \n",
      "     |  igamma(...)\n",
      "     |      igamma(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.igamma`\n",
      "     |  \n",
      "     |  igamma_(...)\n",
      "     |      igamma_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.igamma`\n",
      "     |  \n",
      "     |  igammac(...)\n",
      "     |      igammac(other) -> Tensor\n",
      "     |      See :func:`torch.igammac`\n",
      "     |  \n",
      "     |  igammac_(...)\n",
      "     |      igammac_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.igammac`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_add_`.\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (IntTensor or LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(tensor1, dim, index, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_copy_`.\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If :attr:`index` contains duplicate entries, multiple elements from\n",
      "     |          :attr:`tensor` will be copied to the same index of :attr:`self`. The result\n",
      "     |          is nondeterministic since it depends on which copy occurs last.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(tensor1, dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_fill_`.\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(tensor1, indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`.\n",
      "     |      `tensor1` corresponds to `self` in :meth:`torch.Tensor.index_put_`.\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, values, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`values` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, values)`` is equivalent to\n",
      "     |      ``tensor[indices] = values``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          values (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  inner(...)\n",
      "     |      inner(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inner`.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |      is_coalesced() -> bool\n",
      "     |      \n",
      "     |      Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor\n",
      "     |      <sparse-coo-docs>` that is coalesced, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |      is_complex() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a complex data type.\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous(memory_format=torch.contiguous_format) -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in the order specified\n",
      "     |      by memory format.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation\n",
      "     |              order. Default: ``torch.contiguous_format``.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |      Returns true if this tensor resides in pinned memory.\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if both tensors are pointing to the exact same memory (same\n",
      "     |      storage, offset, size and stride).\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |      isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isclose`\n",
      "     |  \n",
      "     |  isfinite(...)\n",
      "     |      isfinite() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isfinite`\n",
      "     |  \n",
      "     |  isinf(...)\n",
      "     |      isinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isinf`\n",
      "     |  \n",
      "     |  isnan(...)\n",
      "     |      isnan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isnan`\n",
      "     |  \n",
      "     |  isneginf(...)\n",
      "     |      isneginf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isneginf`\n",
      "     |  \n",
      "     |  isposinf(...)\n",
      "     |      isposinf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isposinf`\n",
      "     |  \n",
      "     |  isreal(...)\n",
      "     |      isreal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.isreal`\n",
      "     |  \n",
      "     |  istft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, normalized:bool=False, onesided:Union[bool, NoneType]=None, length:Union[int, NoneType]=None, return_complex:bool=False)\n",
      "     |      See :func:`torch.istft`\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kron(...)\n",
      "     |      kron(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.kron`\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  lcm(...)\n",
      "     |      lcm(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lcm`\n",
      "     |  \n",
      "     |  lcm_(...)\n",
      "     |      lcm_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lcm`\n",
      "     |  \n",
      "     |  ldexp(...)\n",
      "     |      ldexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ldexp`\n",
      "     |  \n",
      "     |  ldexp_(...)\n",
      "     |      ldexp_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ldexp`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`.\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`.\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  less(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less`.\n",
      "     |  \n",
      "     |  less_(...)\n",
      "     |      less_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less`.\n",
      "     |  \n",
      "     |  less_equal(...)\n",
      "     |      less_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.less_equal`.\n",
      "     |  \n",
      "     |  less_equal_(...)\n",
      "     |      less_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.less_equal`.\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |      lgamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lgamma`\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |      lgamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lgamma`\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logaddexp(...)\n",
      "     |      logaddexp(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp`\n",
      "     |  \n",
      "     |  logaddexp2(...)\n",
      "     |      logaddexp2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logaddexp2`\n",
      "     |  \n",
      "     |  logcumsumexp(...)\n",
      "     |      logcumsumexp(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logcumsumexp`\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logical_and(...)\n",
      "     |      logical_and() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_and`\n",
      "     |  \n",
      "     |  logical_and_(...)\n",
      "     |      logical_and_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_and`\n",
      "     |  \n",
      "     |  logical_not(...)\n",
      "     |      logical_not() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_not`\n",
      "     |  \n",
      "     |  logical_not_(...)\n",
      "     |      logical_not_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_not`\n",
      "     |  \n",
      "     |  logical_or(...)\n",
      "     |      logical_or() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_or`\n",
      "     |  \n",
      "     |  logical_or_(...)\n",
      "     |      logical_or_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_or`\n",
      "     |  \n",
      "     |  logical_xor(...)\n",
      "     |      logical_xor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logical_xor`\n",
      "     |  \n",
      "     |  logical_xor_(...)\n",
      "     |      logical_xor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logical_xor`\n",
      "     |  \n",
      "     |  logit(...)\n",
      "     |      logit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logit`\n",
      "     |  \n",
      "     |  logit_(...)\n",
      "     |      logit_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.logit`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  lstsq(...)\n",
      "     |      lstsq(A) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.lstsq`\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`.\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      True. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is True.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (BoolTensor): the boolean mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_exp(...)\n",
      "     |      matrix_exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_exp`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  maximum(...)\n",
      "     |      maximum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.maximum`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  minimum(...)\n",
      "     |      minimum(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.minimum`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  moveaxis(...)\n",
      "     |      moveaxis(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.moveaxis`\n",
      "     |  \n",
      "     |  movedim(...)\n",
      "     |      movedim(source, destination) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.movedim`\n",
      "     |  \n",
      "     |  msort(...)\n",
      "     |      msort() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.msort`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`.\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`.\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  multiply(...)\n",
      "     |      multiply(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multiply`.\n",
      "     |  \n",
      "     |  multiply_(...)\n",
      "     |      multiply_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.multiply`.\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  nan_to_num(...)\n",
      "     |      nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nan_to_num`.\n",
      "     |  \n",
      "     |  nan_to_num_(...)\n",
      "     |      nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.nan_to_num`.\n",
      "     |  \n",
      "     |  nanmedian(...)\n",
      "     |      nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.nanmedian`\n",
      "     |  \n",
      "     |  nanquantile(...)\n",
      "     |      nanquantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nanquantile`\n",
      "     |  \n",
      "     |  nansum(...)\n",
      "     |      nansum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nansum`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`.\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`.\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  negative(...)\n",
      "     |      negative() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.negative`\n",
      "     |  \n",
      "     |  negative_(...)\n",
      "     |      negative_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.negative`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_empty_strided(...)\n",
      "     |      new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with\n",
      "     |      uninitialized data. By default, the returned Tensor has the same\n",
      "     |      :class:`torch.dtype` and :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty_strided((2, 3), (3, 1))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nextafter(...)\n",
      "     |      nextafter(other) -> Tensor\n",
      "     |      See :func:`torch.nextafter`\n",
      "     |  \n",
      "     |  nextafter_(...)\n",
      "     |      nextafter_(other) -> Tensor\n",
      "     |      In-place version of :meth:`~Tensor.nextafter`\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  not_equal(...)\n",
      "     |      not_equal(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.not_equal`.\n",
      "     |  \n",
      "     |  not_equal_(...)\n",
      "     |      not_equal_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.not_equal`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  outer(...)\n",
      "     |      outer(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.outer`.\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor with its dimensions permuted.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |      polygamma(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.polygamma`\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |      polygamma_(n) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.polygamma`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |          ...                     [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_per_channel_axis(...)\n",
      "     |      q_per_channel_axis() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns the index of dimension on which per-channel quantization is applied.\n",
      "     |  \n",
      "     |  q_per_channel_scales(...)\n",
      "     |      q_per_channel_scales() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a Tensor of scales of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_per_channel_zero_points(...)\n",
      "     |      q_per_channel_zero_points() -> Tensor\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear (affine) per-channel quantization,\n",
      "     |      returns a tensor of zero_points of the underlying quantizer. It has the number of\n",
      "     |      elements that matches the corresponding dimensions (from q_per_channel_axis) of\n",
      "     |      the tensor.\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr(some=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  qscheme(...)\n",
      "     |      qscheme() -> torch.qscheme\n",
      "     |      \n",
      "     |      Returns the quantization scheme of a given QTensor.\n",
      "     |  \n",
      "     |  quantile(...)\n",
      "     |      quantile(q, dim=None, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.quantile`\n",
      "     |  \n",
      "     |  rad2deg(...)\n",
      "     |      rad2deg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rad2deg`\n",
      "     |  \n",
      "     |  rad2deg_(...)\n",
      "     |      rad2deg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rad2deg`\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  ravel(...)\n",
      "     |      ravel(input) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.ravel`\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |      record_stream(stream)\n",
      "     |      \n",
      "     |      Ensures that the tensor memory is not reused for another tensor until all\n",
      "     |      current work queued on :attr:`stream` are complete.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The caching allocator is aware of only the stream where a tensor was\n",
      "     |          allocated. Due to the awareness, it already correctly manages the life\n",
      "     |          cycle of tensors on only one stream. But if a tensor is used on a stream\n",
      "     |          different from the stream of origin, the allocator might reuse the memory\n",
      "     |          unexpectedly. Calling this method lets the allocator know which streams\n",
      "     |          have used the tensor.\n",
      "     |  \n",
      "     |  refine_names(self, *names)\n",
      "     |      Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "     |      \n",
      "     |      Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "     |      A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "     |      refined to have the same name.\n",
      "     |      \n",
      "     |      Because named tensors can coexist with unnamed tensors, refining names\n",
      "     |      gives a nice way to write named-tensor-aware code that works with both\n",
      "     |      named and unnamed tensors.\n",
      "     |      \n",
      "     |      :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "     |      The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "     |      :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "     |      corresponding indices of ``self.names``.\n",
      "     |      \n",
      "     |      Python 2 does not support Ellipsis but one may use a string literal\n",
      "     |      instead (``'...'``).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          names (iterable of str): The desired names of the output tensor. May\n",
      "     |              contain up to one Ellipsis.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "     |          >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "     |          >>> named_imgs.names\n",
      "     |          ('N', 'C', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "     |          >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "     |          >>> tensor.names\n",
      "     |          ('A', None, None, 'B', 'C')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  rename(self, *names, **rename_map)\n",
      "     |      Renames dimension names of :attr:`self`.\n",
      "     |      \n",
      "     |      There are two main usages:\n",
      "     |      \n",
      "     |      ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "     |      renamed as specified in the mapping :attr:`rename_map`.\n",
      "     |      \n",
      "     |      ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "     |      dimensions positionally using :attr:`names`.\n",
      "     |      Use ``self.rename(None)`` to drop names on a tensor.\n",
      "     |      \n",
      "     |      One cannot specify both positional args :attr:`names` and keyword args\n",
      "     |      :attr:`rename_map`.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "     |          >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channels', 'H', 'W')\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename(None)\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          (None,)\n",
      "     |      \n",
      "     |          >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "     |          >>> renamed_imgs.names\n",
      "     |          ('batch', 'channel', 'height', 'width')\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  rename_(self, *names, **rename_map)\n",
      "     |      In-place version of :meth:`~Tensor.rename`.\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :meth:`~Tensor.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`requires_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              Tensor. Default: ``torch.contiguous_format``. Note that memory format of\n",
      "     |              :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src, reduce=None) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have\n",
      "     |      the same number of dimensions. It is also required that\n",
      "     |      ``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that\n",
      "     |      ``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.\n",
      "     |      Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When indices are not unique, the behavior is non-deterministic (one of the\n",
      "     |          values from ``src`` will be picked arbitrarily) and the gradient will be\n",
      "     |          incorrect (it will be propagated to all locations in the source that\n",
      "     |          correspond to the same index)!\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Additionally accepts an optional :attr:`reduce` argument that allows\n",
      "     |      specification of an optional reduction operation, which is applied to all\n",
      "     |      values in the tensor :attr:`src` into :attr:`self` at the indicies\n",
      "     |      specified in the :attr:`index`. For each value in :attr:`src`, the reduction\n",
      "     |      operation is applied to an index in :attr:`self` which is specified by\n",
      "     |      its index in :attr:`src` for ``dimension != dim`` and by the corresponding\n",
      "     |      value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`\n",
      "     |      is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      Reducing with the addition operation is the same as using\n",
      "     |      :meth:`~torch.Tensor.scatter_add_`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter, can be either empty\n",
      "     |              or of the same dimensionality as ``src``. When empty, the operation\n",
      "     |              returns ``self`` unchanged.\n",
      "     |          src (Tensor or float): the source element(s) to scatter.\n",
      "     |          reduce (str, optional): reduction operation to apply, can be either\n",
      "     |              ``'add'`` or ``'multiply'``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.arange(1, 11).reshape((2, 5))\n",
      "     |          >>> src\n",
      "     |          tensor([[ 1,  2,  3,  4,  5],\n",
      "     |                  [ 6,  7,  8,  9, 10]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\n",
      "     |          tensor([[1, 0, 0, 4, 0],\n",
      "     |                  [0, 2, 0, 0, 0],\n",
      "     |                  [0, 0, 3, 0, 0]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\n",
      "     |          tensor([[1, 2, 3, 0, 0],\n",
      "     |                  [6, 7, 0, 0, 8],\n",
      "     |                  [0, 0, 0, 0, 0]])\n",
      "     |      \n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='multiply')\n",
      "     |          tensor([[2.0000, 2.0000, 2.4600, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 2.4600]])\n",
      "     |          >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
      "     |          ...            1.23, reduce='add')\n",
      "     |          tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
      "     |                  [2.0000, 2.0000, 2.0000, 3.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`src`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``. Note that ``index`` and ``src`` do not broadcast.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          This operation may behave nondeterministically when given tensors on a CUDA device. See :doc:`/notes/randomness` for more information.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The backward pass is implemented only for ``src.shape == index.shape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add, can be\n",
      "     |              either empty or of the same dimensionality as ``src``. When empty, the\n",
      "     |              operation returns ``self`` unchanged.\n",
      "     |          src (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.ones((2, 5))\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[1., 0., 0., 1., 1.],\n",
      "     |                  [0., 1., 0., 0., 0.],\n",
      "     |                  [0., 0., 1., 0., 0.]])\n",
      "     |          >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n",
      "     |          >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\n",
      "     |          tensor([[2., 0., 0., 1., 1.],\n",
      "     |                  [0., 2., 0., 0., 0.],\n",
      "     |                  [0., 0., 2., 1., 1.]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a view of the original tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  sgn(...)\n",
      "     |      sgn() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sgn`\n",
      "     |  \n",
      "     |  sgn_(...)\n",
      "     |      sgn_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sgn`\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short(memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  signbit(...)\n",
      "     |      signbit() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.signbit`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinc(...)\n",
      "     |      sinc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinc`\n",
      "     |  \n",
      "     |  sinc_(...)\n",
      "     |      sinc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinc`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |      smm(mat) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.smm`\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new :ref:`sparse tensor <sparse-docs>` with values from a\n",
      "     |      strided tensor :attr:`self` filtered by the indices of the sparse\n",
      "     |      tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are\n",
      "     |      ignored. :attr:`self` and :attr:`mask` tensors must have the same\n",
      "     |      shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        The returned sparse tensor has the same indices as the sparse tensor\n",
      "     |        :attr:`mask`, even when the corresponding values in :attr:`self` are\n",
      "     |        zeros.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (Tensor): a sparse tensor whose indices are used as a filter\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nse = 5\n",
      "     |          >>> dims = (5, 5, 2, 2)\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),\n",
      "     |          ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)\n",
      "     |          >>> V = torch.randn(nse, dims[2], dims[3])\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |      sparse_resize_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        If the number of specified elements in :attr:`self` is zero, then\n",
      "     |        :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any\n",
      "     |        size and positive integers such that ``len(size) == sparse_dim +\n",
      "     |        dense_dim``.\n",
      "     |      \n",
      "     |        If :attr:`self` specifies one or more elements, however, then each\n",
      "     |        dimension in :attr:`size` must not be smaller than the corresponding\n",
      "     |        dimension of :attr:`self`, :attr:`sparse_dim` must equal the number\n",
      "     |        of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must\n",
      "     |        equal the number of dense dimensions in :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size. If :attr:`self` is non-empty\n",
      "     |            sparse tensor, the desired size cannot be smaller than the\n",
      "     |            original size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |      sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor\n",
      "     |      \n",
      "     |      Removes all specified elements from a :ref:`sparse tensor\n",
      "     |      <sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired\n",
      "     |      size and the number of sparse and dense dimensions.\n",
      "     |      \n",
      "     |      .. warning:\n",
      "     |        Throws an error if :attr:`self` is not a sparse tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (torch.Size): the desired size.\n",
      "     |          sparse_dim (int): the number of sparse dimensions\n",
      "     |          dense_dim (int): the number of dense dimensions\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  square(...)\n",
      "     |      square() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.square`\n",
      "     |  \n",
      "     |  square_(...)\n",
      "     |      square_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.square`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |      sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sspaddmm`\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft:int, hop_length:Union[int, NoneType]=None, win_length:Union[int, NoneType]=None, window:'Optional[Tensor]'=None, center:bool=True, pad_mode:str='reflect', normalized:bool=False, onesided:Union[bool, NoneType]=None, return_complex:Union[bool, NoneType]=None)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>> x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sub`.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  subtract(...)\n",
      "     |      subtract(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.subtract`.\n",
      "     |  \n",
      "     |  subtract_(...)\n",
      "     |      subtract_(other, *, alpha=1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.subtract`.\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  swapaxes(...)\n",
      "     |      swapaxes(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapaxes`\n",
      "     |  \n",
      "     |  swapaxes_(...)\n",
      "     |      swapaxes_(axis0, axis1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapaxes`\n",
      "     |  \n",
      "     |  swapdims(...)\n",
      "     |      swapdims(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.swapdims`\n",
      "     |  \n",
      "     |  swapdims_(...)\n",
      "     |      swapdims_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.swapdims`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  tensor_split(...)\n",
      "     |      tensor_split(indices_or_sections, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.tensor_split`\n",
      "     |  \n",
      "     |  tile(...)\n",
      "     |      tile(*reps) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tile`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |              memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |      to_dense() -> Tensor\n",
      "     |      \n",
      "     |      Creates a strided copy of :attr:`self`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is a strided tensor.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> s = torch.sparse_coo_tensor(\n",
      "     |          ...        torch.tensor([[1, 1],\n",
      "     |          ...                      [0, 2]]),\n",
      "     |          ...        torch.tensor([9, 10]),\n",
      "     |          ...        size=(3, 3))\n",
      "     |          >>> s.to_dense()\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  true_divide(...)\n",
      "     |      true_divide(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.true_divide`\n",
      "     |  \n",
      "     |  true_divide_(...)\n",
      "     |      true_divide_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.true_divide_`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unflatten(self, dim, sizes)\n",
      "     |      Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "     |      of sizes given by :attr:`sizes`.\n",
      "     |      \n",
      "     |      * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "     |        as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "     |        if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "     |        of elements in the original dim being unflattened.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (Union[int, str]): Dimension to unflatten\n",
      "     |          sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "     |          torch.Size([3, 2, 2, 1])\n",
      "     |          >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "     |          tensor([[[-1.1772,  0.0180],\n",
      "     |                  [ 0.2412,  0.1431]],\n",
      "     |      \n",
      "     |                  [[-1.1819, -0.8899],\n",
      "     |                  [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a view of the original tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsafe_chunk(...)\n",
      "     |      unsafe_chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_chunk`\n",
      "     |  \n",
      "     |  unsafe_split(...)\n",
      "     |      unsafe_split(split_size, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.unsafe_split`\n",
      "     |  \n",
      "     |  unsafe_split_with_sizes(...)\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        Throws an error if :attr:`self` is not a sparse COO tensor.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  vdot(...)\n",
      "     |      vdot(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.vdot`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "     |      without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "     |      :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "     |      returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "     |      :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |      \n",
      "     |      \n",
      "     |      .. function:: view(dtype) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`dtype`. :attr:`dtype` must have the same number of bytes per\n",
      "     |      element as :attr:`self`'s dtype.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This overload is not supported by TorchScript, and using it in a Torchscript\n",
      "     |          program will cause undefined behavior.\n",
      "     |      \n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`): the desired dtype\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |          >>> x.dtype\n",
      "     |          torch.float32\n",
      "     |      \n",
      "     |          >>> y = x.view(torch.int32)\n",
      "     |          >>> y\n",
      "     |          tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],\n",
      "     |                  [-1105482831,  1061112040,  1057999968, -1084397505],\n",
      "     |                  [-1071760287, -1123489973, -1097310419, -1084649136],\n",
      "     |                  [-1101533110,  1073668768, -1082790149, -1088634448]],\n",
      "     |              dtype=torch.int32)\n",
      "     |          >>> y[0, 0] = 1000000000\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],\n",
      "     |                  [-0.1520,  0.7472,  0.5617, -0.8649],\n",
      "     |                  [-2.4724, -0.0334, -0.2976, -0.8499],\n",
      "     |                  [-0.2109,  1.9913, -0.9607, -0.6123]])\n",
      "     |      \n",
      "     |          >>> x.view(torch.int16)\n",
      "     |          Traceback (most recent call last):\n",
      "     |            File \"<stdin>\", line 1, in <module>\n",
      "     |          RuntimeError: Viewing a tensor as a new dtype with a different number of bytes per element is not supported.\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  xlogy(...)\n",
      "     |      xlogy(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.xlogy`\n",
      "     |  \n",
      "     |  xlogy_(...)\n",
      "     |      xlogy_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.xlogy`\n",
      "     |  \n",
      "     |  xpu(...)\n",
      "     |      xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in XPU memory.\n",
      "     |      \n",
      "     |      If this object is already in XPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination XPU device.\n",
      "     |              Defaults to the current XPU device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |          memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "     |              returned Tensor. Default: ``torch.preserve_format``.\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __torch_function__(func, types, args=(), kwargs=None) from torch.tensortype\n",
      "     |      This __torch_function__ implementation wraps subclasses such that\n",
      "     |      methods called on subclasses return a subclass instance instead of\n",
      "     |      a ``torch.Tensor`` instance.\n",
      "     |      \n",
      "     |      One corollary to this is that you need coverage for torch.Tensor\n",
      "     |      methods if implementing __torch_function__ for subclasses.\n",
      "     |      \n",
      "     |      We recommend always calling ``super().__torch_function__`` as the base\n",
      "     |      case when doing the above.\n",
      "     |      \n",
      "     |      While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  T\n",
      "     |      Is this Tensor with its dimensions reversed.\n",
      "     |      \n",
      "     |      If ``n`` is the number of dimensions in ``x``,\n",
      "     |      ``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  imag\n",
      "     |      Returns a new tensor containing imaginary values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`imag` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.imag\n",
      "     |          tensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_meta\n",
      "     |      Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors\n",
      "     |      are like normal tensors, but they carry no data.\n",
      "     |  \n",
      "     |  is_mkldnn\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Is ``True`` if the Tensor is quantized, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_vulkan\n",
      "     |  \n",
      "     |  is_xpu\n",
      "     |      Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  names\n",
      "     |      Stores names for each of this tensor's dimensions.\n",
      "     |      \n",
      "     |      ``names[idx]`` corresponds to the name of tensor dimension ``idx``.\n",
      "     |      Names are either a string if the dimension is named or ``None`` if the\n",
      "     |      dimension is unnamed.\n",
      "     |      \n",
      "     |      Dimension names may contain characters or underscore. Furthermore, a dimension\n",
      "     |      name must be a valid Python variable name (i.e., does not start with underscore).\n",
      "     |      \n",
      "     |      Tensors may not have two named dimensions with the same name.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          The named tensor API is experimental and subject to change.\n",
      "     |  \n",
      "     |  ndim\n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  real\n",
      "     |      Returns a new tensor containing real values of the :attr:`self` tensor.\n",
      "     |      The returned tensor and :attr:`self` share the same underlying storage.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |          :func:`real` is only supported for tensors with complex dtypes.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x=torch.randn(4, dtype=torch.cfloat)\n",
      "     |          >>> x\n",
      "     |          tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n",
      "     |          >>> x.real\n",
      "     |          tensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int16\n",
      "     |  \n",
      "     |  is_cuda = True\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class cudaStatus(builtins.object)\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ERROR_NOT_READY = 34\n",
      "     |  \n",
      "     |  SUCCESS = 0\n",
      "     |  \n",
      "     |  __annotations__ = {'ERROR_NOT_READY': <class 'int'>, 'SUCCESS': <class...\n",
      "    \n",
      "    class device(builtins.object)\n",
      "     |  Context-manager that changes the selected device.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      device (torch.device or int): device index to select. It's a no-op if\n",
      "     |          this argument is a negative integer or ``None``.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self, device)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class device_of(device)\n",
      "     |  Context-manager that changes the current device to that of given object.\n",
      "     |  \n",
      "     |  You can use both tensors and storages as arguments. If a given object is\n",
      "     |  not allocated on a GPU, this is a no-op.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      obj (Tensor or Storage): object allocated on the selected device.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      device_of\n",
      "     |      device\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, obj)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from device:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from device:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    can_device_access_peer(device:Union[torch.device, str, int, NoneType], peer_device:Union[torch.device, str, int, NoneType]) -> bool\n",
      "        Checks if peer access between two devices is possible.\n",
      "    \n",
      "    check_error(res:int) -> None\n",
      "    \n",
      "    cudart()\n",
      "    \n",
      "    current_blas_handle()\n",
      "        Returns cublasHandle_t pointer to current cuBLAS handle\n",
      "    \n",
      "    current_device() -> int\n",
      "        Returns the index of a currently selected device.\n",
      "    \n",
      "    current_stream(device:Union[torch.device, str, int, NoneType]=None) -> torch.cuda.streams.Stream\n",
      "        Returns the currently selected :class:`Stream` for a given device.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int, optional): selected device. Returns\n",
      "                the currently selected :class:`Stream` for the current device, given\n",
      "                by :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n",
      "                (default).\n",
      "    \n",
      "    default_stream(device:Union[torch.device, str, int, NoneType]=None) -> torch.cuda.streams.Stream\n",
      "        Returns the default :class:`Stream` for a given device.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int, optional): selected device. Returns\n",
      "                the default :class:`Stream` for the current device, given by\n",
      "                :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n",
      "                (default).\n",
      "    \n",
      "    device_count() -> int\n",
      "        Returns the number of GPUs available.\n",
      "    \n",
      "    get_arch_list() -> List[str]\n",
      "        Returns list CUDA architectures this library was compiled for.\n",
      "    \n",
      "    get_device_capability(device:Union[torch.device, str, int, NoneType]=None) -> Tuple[int, int]\n",
      "        Gets the cuda capability of a device.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int, optional): device for which to return the\n",
      "                device capability. This function is a no-op if this argument is\n",
      "                a negative integer. It uses the current device, given by\n",
      "                :func:`~torch.cuda.current_device`, if :attr:`device` is ``None``\n",
      "                (default).\n",
      "        \n",
      "        Returns:\n",
      "            tuple(int, int): the major and minor cuda capability of the device\n",
      "    \n",
      "    get_device_name(device:Union[torch.device, str, int, NoneType]=None) -> str\n",
      "        Gets the name of a device.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int, optional): device for which to return the\n",
      "                name. This function is a no-op if this argument is a negative\n",
      "                integer. It uses the current device, given by :func:`~torch.cuda.current_device`,\n",
      "                if :attr:`device` is ``None`` (default).\n",
      "        \n",
      "        Returns:\n",
      "            str: the name of the device\n",
      "    \n",
      "    get_device_properties(device:Union[torch.device, str, int, NoneType]) -> torch._C._CudaDeviceProperties\n",
      "        Gets the properties of a device.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int or str): device for which to return the\n",
      "                properties of the device.\n",
      "        \n",
      "        Returns:\n",
      "            _CudaDeviceProperties: the properties of the device\n",
      "    \n",
      "    get_gencode_flags() -> str\n",
      "        Returns NVCC gencode flags this library were compiled with.\n",
      "    \n",
      "    init()\n",
      "        Initialize PyTorch's CUDA state.  You may need to call\n",
      "        this explicitly if you are interacting with PyTorch via\n",
      "        its C API, as Python bindings for CUDA functionality will not\n",
      "        be available until this initialization takes place.  Ordinary users\n",
      "        should not need this, as all of PyTorch's CUDA methods\n",
      "        automatically initialize CUDA state on-demand.\n",
      "        \n",
      "        Does nothing if the CUDA state is already initialized.\n",
      "    \n",
      "    ipc_collect()\n",
      "        Force collects GPU memory after it has been released by CUDA IPC.\n",
      "        \n",
      "        .. note::\n",
      "            Checks if any sent CUDA tensors could be cleaned from the memory. Force\n",
      "            closes shared memory file used for reference counting if there is no\n",
      "            active counters. Useful when the producer process stopped actively sending\n",
      "            tensors and want to release unused memory.\n",
      "    \n",
      "    is_available() -> bool\n",
      "        Returns a bool indicating if CUDA is currently available.\n",
      "    \n",
      "    is_initialized()\n",
      "        Returns whether PyTorch's CUDA state has been initialized.\n",
      "    \n",
      "    set_device(device:Union[torch.device, str, int, NoneType]) -> None\n",
      "        Sets the current device.\n",
      "        \n",
      "        Usage of this function is discouraged in favor of :any:`device`. In most\n",
      "        cases it's better to use ``CUDA_VISIBLE_DEVICES`` environmental variable.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int): selected device. This function is a no-op\n",
      "                if this argument is negative.\n",
      "    \n",
      "    stream(stream)\n",
      "        Context-manager that selects a given stream.\n",
      "        \n",
      "        All CUDA kernels queued within its context will be enqueued on a selected\n",
      "        stream.\n",
      "        \n",
      "        Args:\n",
      "            stream (Stream): selected stream. This manager is a no-op if it's\n",
      "                ``None``.\n",
      "        \n",
      "        .. note:: Streams are per-device. If the selected stream is not on the\n",
      "            current device, this function will also change the current device to\n",
      "            match the stream.\n",
      "    \n",
      "    synchronize(device:Union[torch.device, str, int, NoneType]=None) -> None\n",
      "        Waits for all kernels in all streams on a CUDA device to complete.\n",
      "        \n",
      "        Args:\n",
      "            device (torch.device or int, optional): device for which to synchronize.\n",
      "                It uses the current device, given by :func:`~torch.cuda.current_device`,\n",
      "                if :attr:`device` is ``None`` (default).\n",
      "\n",
      "DATA\n",
      "    Any = typing.Any\n",
      "    Device = typing.Union[torch.device, str, NoneType]\n",
      "    Optional = typing.Optional\n",
      "    Union = typing.Union\n",
      "    __annotations__ = {'default_generators': typing.Tuple[torch._C.Generat...\n",
      "    default_generators = ()\n",
      "    has_half = False\n",
      "    has_magma = False\n",
      "\n",
      "FILE\n",
      "    /data/yyx/anaconda3/envs/python36/lib/python3.6/site-packages/torch/cuda/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Returns a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "涉及两个类：Dataset、Dataloader\n",
    "Dataset：提供一种方式去获取数据及其label，并告诉总共数据量多少...<br />\n",
    "Dataloader：为后面的网络提供不同的数据形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x512 at 0x7F5C23E13860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=Image.open(\"./数据集/train/ants_image/0013035.jpg\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0013035.jpg',\n",
       " '1030023514_aad5c608f9.jpg',\n",
       " '1095476100_3906d8afde.jpg',\n",
       " '1099452230_d1949d3250.jpg',\n",
       " '116570827_e9c126745d.jpg',\n",
       " '1225872729_6f0856588f.jpg',\n",
       " '1262877379_64fcada201.jpg',\n",
       " '1269756697_0bce92cdab.jpg',\n",
       " '1286984635_5119e80de1.jpg',\n",
       " '132478121_2a430adea2.jpg',\n",
       " '1360291657_dc248c5eea.jpg',\n",
       " '1368913450_e146e2fb6d.jpg',\n",
       " '1473187633_63ccaacea6.jpg',\n",
       " '148715752_302c84f5a4.jpg',\n",
       " '1489674356_09d48dde0a.jpg',\n",
       " '149244013_c529578289.jpg',\n",
       " '150801003_3390b73135.jpg',\n",
       " '150801171_cd86f17ed8.jpg',\n",
       " '154124431_65460430f2.jpg',\n",
       " '162603798_40b51f1654.jpg',\n",
       " '1660097129_384bf54490.jpg',\n",
       " '167890289_dd5ba923f3.jpg',\n",
       " '1693954099_46d4c20605.jpg',\n",
       " '175998972.jpg',\n",
       " '178538489_bec7649292.jpg',\n",
       " '1804095607_0341701e1c.jpg',\n",
       " '1808777855_2a895621d7.jpg',\n",
       " '188552436_605cc9b36b.jpg',\n",
       " '1917341202_d00a7f9af5.jpg',\n",
       " '1924473702_daa9aacdbe.jpg',\n",
       " '196057951_63bf063b92.jpg',\n",
       " '196757565_326437f5fe.jpg',\n",
       " '201558278_fe4caecc76.jpg',\n",
       " '201790779_527f4c0168.jpg',\n",
       " '2019439677_2db655d361.jpg',\n",
       " '207947948_3ab29d7207.jpg',\n",
       " '20935278_9190345f6b.jpg',\n",
       " '224655713_3956f7d39a.jpg',\n",
       " '2265824718_2c96f485da.jpg',\n",
       " '2265825502_fff99cfd2d.jpg',\n",
       " '226951206_d6bf946504.jpg',\n",
       " '2278278459_6b99605e50.jpg',\n",
       " '2288450226_a6e96e8fdf.jpg',\n",
       " '2288481644_83ff7e4572.jpg',\n",
       " '2292213964_ca51ce4bef.jpg',\n",
       " '24335309_c5ea483bb8.jpg',\n",
       " '245647475_9523dfd13e.jpg',\n",
       " '255434217_1b2b3fe0a4.jpg',\n",
       " '258217966_d9d90d18d3.jpg',\n",
       " '275429470_b2d7d9290b.jpg',\n",
       " '28847243_e79fe052cd.jpg',\n",
       " '318052216_84dff3f98a.jpg',\n",
       " '334167043_cbd1adaeb9.jpg',\n",
       " '339670531_94b75ae47a.jpg',\n",
       " '342438950_a3da61deab.jpg',\n",
       " '36439863_0bec9f554f.jpg',\n",
       " '374435068_7eee412ec4.jpg',\n",
       " '382971067_0bfd33afe0.jpg',\n",
       " '384191229_5779cf591b.jpg',\n",
       " '386190770_672743c9a7.jpg',\n",
       " '392382602_1b7bed32fa.jpg',\n",
       " '403746349_71384f5b58.jpg',\n",
       " '408393566_b5b694119b.jpg',\n",
       " '424119020_6d57481dab.jpg',\n",
       " '424873399_47658a91fb.jpg',\n",
       " '450057712_771b3bfc91.jpg',\n",
       " '45472593_bfd624f8dc.jpg',\n",
       " '459694881_ac657d3187.jpg',\n",
       " '460372577_f2f6a8c9fc.jpg',\n",
       " '460874319_0a45ab4d05.jpg',\n",
       " '466430434_4000737de9.jpg',\n",
       " '470127037_513711fd21.jpg',\n",
       " '474806473_ca6caab245.jpg',\n",
       " '475961153_b8c13fd405.jpg',\n",
       " '484293231_e53cfc0c89.jpg',\n",
       " '49375974_e28ba6f17e.jpg',\n",
       " '506249802_207cd979b4.jpg',\n",
       " '506249836_717b73f540.jpg',\n",
       " '512164029_c0a66b8498.jpg',\n",
       " '512863248_43c8ce579b.jpg',\n",
       " '518773929_734dbc5ff4.jpg',\n",
       " '522163566_fec115ca66.jpg',\n",
       " '522415432_2218f34bf8.jpg',\n",
       " '531979952_bde12b3bc0.jpg',\n",
       " '533848102_70a85ad6dd.jpg',\n",
       " '535522953_308353a07c.jpg',\n",
       " '540889389_48bb588b21.jpg',\n",
       " '541630764_dbd285d63c.jpg',\n",
       " '543417860_b14237f569.jpg',\n",
       " '560966032_988f4d7bc4.jpg',\n",
       " '5650366_e22b7e1065.jpg',\n",
       " '6240329_72c01e663e.jpg',\n",
       " '6240338_93729615ec.jpg',\n",
       " '649026570_e58656104b.jpg',\n",
       " '662541407_ff8db781e7.jpg',\n",
       " '67270775_e9fdf77e9d.jpg',\n",
       " '6743948_2b8c096dda.jpg',\n",
       " '684133190_35b62c0c1d.jpg',\n",
       " '69639610_95e0de17aa.jpg',\n",
       " '707895295_009cf23188.jpg',\n",
       " 'Ant_1.jpg',\n",
       " '7759525_1363d24e88.jpg',\n",
       " '795000156_a9900a4a71.jpg',\n",
       " '822537660_caf4ba5514.jpg',\n",
       " '82852639_52b7f7f5e3.jpg',\n",
       " '841049277_b28e58ad05.jpg',\n",
       " '886401651_f878e888cd.jpg',\n",
       " '892108839_f1aad4ca46.jpg',\n",
       " '938946700_ca1c669085.jpg',\n",
       " '957233405_25c1d1187b.jpg',\n",
       " '9715481_b3cb4114ff.jpg',\n",
       " '998118368_6ac1d91f81.jpg',\n",
       " 'ant photos.jpg',\n",
       " 'army-ants-red-picture.jpg',\n",
       " 'formica.jpeg',\n",
       " 'hormiga_co_por.jpg',\n",
       " 'imageNotFound.gif',\n",
       " 'kurokusa.jpg',\n",
       " 'MehdiabadiAnt2_600.jpg',\n",
       " 'Nepenthes_rafflesiana_ant.jpg',\n",
       " 'swiss-army-ant.jpg',\n",
       " 'termite-vs-ant.jpg',\n",
       " 'trap-jaw-ant-insect-bg.jpg',\n",
       " 'VietnameseAntMimicSpider.jpg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path=\"数据集/train/ants_image\"\n",
    "img_path_list=os.listdir(dir_path)\n",
    "img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0013035.jpg'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        # rood_dir=\"数据集/train\"\n",
    "        # label_dir=\"ants_image\"\n",
    "        # 所以path=os.path.join(root_dir,label_dir)，一个简单的拼接\n",
    "        self.root_dir=root_dir\n",
    "        self.label_dir=label_dir\n",
    "        self.path=os.path.join(self.root_dir,self.label_dir)\n",
    "        self.img_path=os.listdir(self.path)        \n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        # 读取其中一个图片\n",
    "        img_name=self.img_path[idx]\n",
    "        img_item_path=os.path.join(self.root_dir,self.label_dir,img_name)\n",
    "        img=Image.open(img_item_path)\n",
    "        label=self.label_dir\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        # 告诉总共数据量多少...就是列表长度\n",
    "        return len(self.img_path)\n",
    "\n",
    "root_dir=\"数据集/train\"\n",
    "ants_label_dir=\"ants_image\"\n",
    "ants_dataset=MyData(root_dir,ants_label_dir)\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x512 at 0x7F5C280C01D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label=ants_dataset[0]   \n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7F5C23E69160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bees_label_dir=\"bees_image\"\n",
    "bees_dataset=MyData(root_dir,bees_label_dir)\n",
    "img2,label2=bees_dataset[0]\n",
    "display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset=ants_dataset+bees_dataset\n",
    "len(ants_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bees_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7F5C239CE240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label=train_dataset[124]\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "305.844px",
    "left": "317.377px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
